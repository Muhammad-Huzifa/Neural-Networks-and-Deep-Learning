{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMhHhk6GvR1f02lmsvd9bdb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muhammad-Huzifa/Neural-Networks-and-Deep-Learning/blob/main/Deep%20Neural%20Networks/Deep_Nueral_Networks_SImple_DNNS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soHSVXoFNshG",
        "outputId": "24750443-1053-46d8-c528-dd2198d014fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output (A4): [[0.49999834]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Activation functions and their derivatives\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "# Derivatives of activation functions\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "def relu_derivative(x):\n",
        "    return (x > 0).astype(float)\n",
        "\n",
        "# Initialize the parameters (weights and biases)\n",
        "def initialize_parameters():\n",
        "    np.random.seed(1)\n",
        "\n",
        "    # Weights and biases for each layer\n",
        "    W1 = np.random.randn(5, 3) * 0.1  # 5 neurons, 3 inputs\n",
        "    b1 = np.zeros((5, 1))\n",
        "\n",
        "    W2 = np.random.randn(5, 5) * 0.1  # 5 neurons, 5 inputs (from previous layer)\n",
        "    b2 = np.zeros((5, 1))\n",
        "\n",
        "    W3 = np.random.randn(2, 5) * 0.1  # 2 neurons, 5 inputs (from previous layer)\n",
        "    b3 = np.zeros((2, 1))\n",
        "\n",
        "    W4 = np.random.randn(1, 2) * 0.1  # 1 neuron, 2 inputs (from previous layer)\n",
        "    b4 = np.zeros((1, 1))\n",
        "\n",
        "    parameters = {\n",
        "        \"W1\": W1, \"b1\": b1,\n",
        "        \"W2\": W2, \"b2\": b2,\n",
        "        \"W3\": W3, \"b3\": b3,\n",
        "        \"W4\": W4, \"b4\": b4\n",
        "    }\n",
        "\n",
        "    return parameters\n",
        "\n",
        "# Forward propagation\n",
        "def forward_propagation(X, parameters):\n",
        "    # Retrieve parameters\n",
        "    W1, b1 = parameters[\"W1\"], parameters[\"b1\"]\n",
        "    W2, b2 = parameters[\"W2\"], parameters[\"b2\"]\n",
        "    W3, b3 = parameters[\"W3\"], parameters[\"b3\"]\n",
        "    W4, b4 = parameters[\"W4\"], parameters[\"b4\"]\n",
        "\n",
        "    # Layer 1: Z1 -> A1 (ReLU)\n",
        "    Z1 = np.dot(W1, X) + b1\n",
        "    A1 = relu(Z1)\n",
        "\n",
        "    # Layer 2: Z2 -> A2 (ReLU)\n",
        "    Z2 = np.dot(W2, A1) + b2\n",
        "    A2 = relu(Z2)\n",
        "\n",
        "    # Layer 3: Z3 -> A3 (ReLU)\n",
        "    Z3 = np.dot(W3, A2) + b3\n",
        "    A3 = relu(Z3)\n",
        "\n",
        "    # Layer 4: Z4 -> A4 (Sigmoid)\n",
        "    Z4 = np.dot(W4, A3) + b4\n",
        "    A4 = sigmoid(Z4)\n",
        "\n",
        "    cache = {\n",
        "        \"Z1\": Z1, \"A1\": A1,\n",
        "        \"Z2\": Z2, \"A2\": A2,\n",
        "        \"Z3\": Z3, \"A3\": A3,\n",
        "        \"Z4\": Z4, \"A4\": A4\n",
        "    }\n",
        "\n",
        "    return A4, cache\n",
        "\n",
        "# Example usage\n",
        "X = np.array([[0.1], [0.2], [0.3]])  # Input vector (3 inputs)\n",
        "\n",
        "# Initialize parameters\n",
        "parameters = initialize_parameters()\n",
        "\n",
        "# Perform forward propagation\n",
        "A4, cache = forward_propagation(X, parameters)\n",
        "\n",
        "print(\"Output (A4):\", A4)\n"
      ]
    }
  ]
}